{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447a92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    BaggingRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import (\n",
    "    BayesianRidge,\n",
    "    ElasticNet,\n",
    "    LinearRegression,\n",
    "    SGDRegressor,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "class RegressionObjectives:\n",
    "    def __init__(self, X, y, cv=5, random_state=42, metric=\"r2\"):\n",
    "        self.metric = metric\n",
    "        self.cv = cv\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def lin_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"copy_X\": trial.suggest_categorical(\"copy_X\", [True, False]),\n",
    "        }\n",
    "        regressor = LinearRegression(**param, n_jobs=-1)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def sgd_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"loss\": trial.suggest_categorical(\n",
    "                \"loss\", [\"squared_loss\", \"huber\", \"epsilon_insensitive\"]\n",
    "            ),\n",
    "            \"penalty\": trial.suggest_categorical(\n",
    "                \"penalty\", [\"none\", \"l2\", \"l1\", \"elasticnet\"]\n",
    "            ),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-10, 1e-3),\n",
    "            \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "            \"learning_rate\": trial.suggest_categorical(\n",
    "                \"learning_rate\", [\"constant\", \"optimal\", \"invscaling\", \"adaptive\"]\n",
    "            ),\n",
    "            \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0),\n",
    "            \"power_t\": trial.suggest_float(\"power_t\", 0.0, 1.0),\n",
    "            \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
    "            \"average\": trial.suggest_categorical(\"average\", [True, False]),\n",
    "            \"random_state\": self.random_state,\n",
    "        }\n",
    "        regressor = SGDRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def krr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-10, 1e-3),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"degree\": trial.suggest_int(\"degree\", 1, 3),\n",
    "            \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 1e-3),\n",
    "            \"coef0\": trial.suggest_loguniform(\"coef0\", 1e-10, 1e-3),\n",
    "        }\n",
    "        regressor = KernelRidge(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def elas_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-10, 1e-3),\n",
    "            \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "            \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"]),\n",
    "            \"tol\": trial.suggest_loguniform(\"tol\", 1e-10, 1e-3),\n",
    "            \"random_state\": self.random_state,\n",
    "        }\n",
    "        regressor = ElasticNet(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def br_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"alpha_1\": trial.suggest_loguniform(\"alpha_1\", 1e-10, 1e-3),\n",
    "            \"alpha_2\": trial.suggest_loguniform(\"alpha_2\", 1e-10, 1e-3),\n",
    "            \"lambda_1\": trial.suggest_loguniform(\"lambda_1\", 1e-10, 1e-3),\n",
    "            \"lambda_2\": trial.suggest_loguniform(\"lambda_2\", 1e-10, 1e-3),\n",
    "            \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "            \"normalize\": trial.suggest_categorical(\"normalize\", [True, False]),\n",
    "            \"copy_X\": trial.suggest_categorical(\"copy_X\", [True, False]),\n",
    "        }\n",
    "        regressor = BayesianRidge(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def svr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"C\": trial.suggest_loguniform(\"C\", 1e-10, 1e-3),\n",
    "            \"kernel\": trial.suggest_categorical(\"kernel\", [\"linear\", \"rbf\"]),\n",
    "            \"degree\": trial.suggest_int(\"degree\", 1, 3),\n",
    "            \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-10, 1e-3),\n",
    "            \"coef0\": trial.suggest_loguniform(\"coef0\", 1e-10, 1e-3),\n",
    "            \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "            \"tol\": trial.suggest_loguniform(\"tol\", 1e-10, 1e-3),\n",
    "            \"cache_size\": trial.suggest_loguniform(\"cache_size\", 1e-10, 1e-3),\n",
    "            \"verbose\": trial.suggest_categorical(\"verbose\", [True, False]),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "        }\n",
    "        regressor = SVR(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def knr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 10),\n",
    "            \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "            \"algorithm\": trial.suggest_categorical(\n",
    "                \"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "            ),\n",
    "            \"leaf_size\": trial.suggest_int(\"leaf_size\", 1, 100),\n",
    "            \"p\": trial.suggest_int(\"p\", 1, 3),\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        regressor = KNeighborsRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def dt_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"criterion\": trial.suggest_categorical(\n",
    "                \"criterion\", [\"mse\", \"friedman_mse\", \"mae\"]\n",
    "            ),\n",
    "            \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\", \"random\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"min_weight_fraction_leaf\": trial.suggest_loguniform(\n",
    "                \"min_weight_fraction_leaf\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"max_features\": trial.suggest_categorical(\n",
    "                \"max_features\", [\"auto\", \"sqrt\", \"log2\", None]\n",
    "            ),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 10),\n",
    "            \"min_impurity_decrease\": trial.suggest_loguniform(\n",
    "                \"min_impurity_decrease\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"random_state\": self.random_state,\n",
    "        }\n",
    "        regressor = DecisionTreeRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def gbr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"loss\": trial.suggest_categorical(\n",
    "                \"loss\", [\"ls\", \"lad\", \"huber\", \"quantile\"]\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-10, 1e-3),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "            \"criterion\": trial.suggest_categorical(\n",
    "                \"criterion\", [\"friedman_mse\", \"mae\"]\n",
    "            ),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"min_weight_fraction_leaf\": trial.suggest_loguniform(\n",
    "                \"min_weight_fraction_leaf\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"max_features\": trial.suggest_categorical(\n",
    "                \"max_features\", [\"auto\", \"sqrt\", \"log2\", None]\n",
    "            ),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 10),\n",
    "            \"min_impurity_decrease\": trial.suggest_loguniform(\n",
    "                \"min_impurity_decrease\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"random_state\": self.random_state,\n",
    "        }\n",
    "        regressor = GradientBoostingRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def ada_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-10, 1e-3),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "            \"loss\": trial.suggest_categorical(\n",
    "                \"loss\", [\"linear\", \"square\", \"exponential\"]\n",
    "            ),\n",
    "            \"random_state\": self.random_state,\n",
    "        }\n",
    "        regressor = AdaBoostRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def bag_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "            \"bootstrap_features\": trial.suggest_categorical(\n",
    "                \"bootstrap_features\", [True, False]\n",
    "            ),\n",
    "            \"oob_score\": trial.suggest_categorical(\"oob_score\", [True, False]),\n",
    "            \"max_samples\": trial.suggest_uniform(\"max_samples\", 0.0, 1.0),\n",
    "            \"max_features\": trial.suggest_uniform(\"max_features\", 0.0, 1.0),\n",
    "            \"random_state\": self.random_state,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        regressor = BaggingRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def extr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "            \"criterion\": trial.suggest_categorical(\n",
    "                \"criterion\", [\"mse\", \"friedman_mse\", \"mae\"]\n",
    "            ),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"min_weight_fraction_leaf\": trial.suggest_loguniform(\n",
    "                \"min_weight_fraction_leaf\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"max_features\": trial.suggest_categorical(\n",
    "                \"max_features\", [\"auto\", \"sqrt\", \"log2\", None]\n",
    "            ),\n",
    "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 10),\n",
    "            \"min_impurity_decrease\": trial.suggest_loguniform(\n",
    "                \"min_impurity_decrease\", 1e-10, 1e-3\n",
    "            ),\n",
    "            \"bootstrap\": True,\n",
    "            \"oob_score\": trial.suggest_categorical(\"oob_score\", [True, False]),\n",
    "            \"random_state\": self.random_state,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "        regressor = ExtraTreesRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def rfr_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 80, log=True),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 15),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 9),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        }\n",
    "        regressor = RandomForestRegressor(**param, n_jobs=-1, verbose=0)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def xgb_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 500, 4000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 8, 16),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 300),\n",
    "            \"gamma\": trial.suggest_int(\"gamma\", 1, 3),\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"colsample_bytree\": trial.suggest_discrete_uniform(\n",
    "                \"colsample_bytree\", 0.5, 1, 0.1\n",
    "            ),\n",
    "            \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n",
    "            \"subsample\": trial.suggest_categorical(\"subsample\", [0.6, 0.7, 0.8, 1.0]),\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "        regressor = XGBRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def cat_regressor_objective(self, trial):\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 50, 300),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "            \"random_strength\": trial.suggest_int(\"random_strength\", 0, 100),\n",
    "            \"bagging_temperature\": trial.suggest_loguniform(\n",
    "                \"bagging_temperature\", 0.01, 100.00\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 1e-1),\n",
    "            \"od_type\": trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        }\n",
    "        regressor = CatBoostRegressor(**params)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def lgbm_regressor_objective(self, trial):\n",
    "\n",
    "        param = {\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"rmse\",\n",
    "            \"learning_rate\": trial.suggest_categorical(\n",
    "                \"learning_rate\", [0.0125, 0.025, 0.05, 0.1]\n",
    "            ),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2048),\n",
    "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "            \"colsample_bytree\": min(\n",
    "                trial.suggest_float(\"colsample_bytree\", 0.3, 1.0 + 1e-8), 1.0\n",
    "            ),\n",
    "            \"bagging_fraction\": min(\n",
    "                trial.suggest_float(\"bagging_fraction\", 0.3, 1.0 + 1e-8), 1.0\n",
    "            ),\n",
    "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "            \"feature_pre_filter\": False,\n",
    "            \"random_state\": self.random_state,\n",
    "            \"num_threads\": -1,\n",
    "            \"extra_trees\": trial.suggest_categorical(\"extra_trees\", [True, False]),\n",
    "        }\n",
    "        regressor = LGBMRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()\n",
    "\n",
    "    def mlp_regressor_objective(self, trial):\n",
    "        param = {\n",
    "            \"hidden_layer_sizes\": trial.suggest_int(\"hidden_layer_sizes\", 2, 10),\n",
    "            \"activation\": trial.suggest_categorical(\"activation\", [\"logistic\", \"tanh\"]),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"adam\"]),\n",
    "            \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-8, 1e-1),\n",
    "            \"learning_rate\": trial.suggest_categorical(\n",
    "                \"learning_rate\", [\"constant\", \"adaptive\"]\n",
    "            ),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 1, 2000),\n",
    "            \"random_state\": self.random_state,\n",
    "            \"verbose\": 0,\n",
    "            \"early_stopping\": True,\n",
    "            \"validation_fraction\": 0.2,\n",
    "            \"n_iter_no_change\": 10,\n",
    "        }\n",
    "        regressor = MLPRegressor(**param)\n",
    "        scores = cross_val_score(\n",
    "            regressor, self.X, self.y, cv=self.cv, n_jobs=-1, scoring=self.metric\n",
    "        )\n",
    "        return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db723557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
