{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72804ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '无敌的表格包'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11740\\2757933653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcolorama\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0m无敌的表格包\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m无敌的命名包\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m无敌的预测包\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_predictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '无敌的表格包'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pickle import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from colorama import Fore\n",
    "from IPython.display import display\n",
    "from 无敌的表格包 import Best\n",
    "from 无敌的命名包 import *\n",
    "from 无敌的预测包 import classification_predictor\n",
    "from 无敌的前置包 import PreProcesser\n",
    "from 无敌的模型优化包 import wudimodel_tuner\n",
    "from 无敌的验证包 import *\n",
    "from optuna.samplers._tpe.sampler import TPESampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4110f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TPESampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11740\\2855016962.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mRegression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     def __init__(\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lin\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11740\\2855016962.py\u001b[0m in \u001b[0;36mRegression\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mexclude_models\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moptuna_sampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultivariate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0moptuna_direction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moptuna_n_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TPESampler' is not defined"
     ]
    }
   ],
   "source": [
    "class Regression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        predictor=[\"lin\"],\n",
    "        params={},\n",
    "        tune=False,\n",
    "        test_size=0.2,\n",
    "        cv_folds=10,\n",
    "        random_state=42,\n",
    "        pca_kernel=\"linear\",\n",
    "        n_components_lda=1,\n",
    "        lda=\"n\",\n",
    "        pca=\"n\",\n",
    "        n_components_pca=2,\n",
    "        loss=\"mean_squared_error\",\n",
    "        validation_split=0.20,\n",
    "        smote=\"n\",\n",
    "        k_neighbors=1,\n",
    "        verbose=False,\n",
    "        exclude_models=[],\n",
    "        path=None,\n",
    "        optuna_sampler=TPESampler(multivariate=True),\n",
    "        optuna_direction=\"maximize\",\n",
    "        optuna_n_trials=100,\n",
    "        optuna_metric=\"r2\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Encodes Categorical Data then Applies SMOTE , Splits the features and labels in training and validation sets with test_size = .2\\n\n",
    "        scales X_train, X_val using StandardScaler.\\n\n",
    "        Fits every model on training set and predicts results,Finds R2 Score and mean square error\\n\n",
    "        finds accuracy of model applies K-Fold Cross Validation\\n\n",
    "        and stores its accuracies in a dictionary containing Model name as Key and accuracies as values and returns it\\n\n",
    "        Applies HyperParam Tuning and gives best params and accuracy.\\n\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "            features : array\n",
    "                        features array\n",
    "            lables : array\n",
    "                        labels array\n",
    "            predictor : list\n",
    "                        Predicting models to be used\n",
    "                        Default ['lin'] - 'Linear Regression'\\n\n",
    "                        Available Predictors:\n",
    "                                lin  - Linear Regression\\n\n",
    "                                sgd  - Stochastic Gradient Descent Regressor\\n\n",
    "                                elas - Elastic Net Regressor\\n\n",
    "                                krr  - Kernel Ridge Regressor\\n\n",
    "                                br   - Bayesian Ridge Regressor\\n\n",
    "                                svr  - Support Vector Regressor\\n\n",
    "                                knr  - K-Nearest Regressor\\n\n",
    "                                dt   - Decision Trees\\n\n",
    "                                rfr  - Random Forest Regressor\\n\n",
    "                                gbr  - Gradient Boost Regressor\\n\n",
    "                                ada  - AdaBoost Regressor,\\n\n",
    "                                bag  - Bagging Regressor,\\n\n",
    "                                extr - Extra Trees Regressor,\\n\n",
    "                                lgbm - LightGB Regressor\\n\n",
    "                                xgb  - XGBoost Regressor\\n\n",
    "                                cat  - Catboost Regressor\\n\n",
    "                                ann  - Multi Layer Perceptron Regressor\\n\n",
    "                                all  - Applies all above regressors\\n\n",
    "            params : dict\n",
    "                        contains parameters for model\n",
    "            tune : boolean\n",
    "                    when True Applies GridSearch CrossValidation\n",
    "                    Default is False\n",
    "            test_size: float or int, default=.2\n",
    "                        If float, should be between 0.0 and 1.0 and represent\n",
    "                        the proportion of the dataset to include in\n",
    "                        the test split.\n",
    "                        If int, represents the absolute number of test samples.\n",
    "            cv_folds : int\n",
    "                    No. of cross validation folds. Default = 10\n",
    "            pca : str\n",
    "                if 'y' will apply PCA on Train and Validation set. Default = 'n'\n",
    "            lda : str\n",
    "                if 'y' will apply LDA on Train and Validation set. Default = 'n'\n",
    "            pca_kernel : str\n",
    "                    Kernel to be use in PCA. Default = 'linear'\n",
    "            n_components_lda : int\n",
    "                    No. of components for LDA. Default = 1\n",
    "            n_components_pca : int\n",
    "                    No. of components for PCA. Default = 2\n",
    "            loss : str\n",
    "                    loss method for ann. Default = 'mean_squared_error'\n",
    "            smote : str,\n",
    "                Whether to apply SMOTE. Default = 'y'\n",
    "            k_neighbors : int\n",
    "                No. of neighbours for SMOTE. Default = 1\n",
    "            verbose : boolean\n",
    "                Verbosity of models. Default = False\n",
    "            exclude_models : list\n",
    "                List of models to be excluded when using predictor = 'all' . Default = []\n",
    "            path : list\n",
    "                List containing path to saved model and scaler. Default = None\n",
    "                Example: [model.pkl, scaler.pkl]\n",
    "            random_state : int\n",
    "                Random random_state for reproducibility. Default = 42\n",
    "            optuna_sampler : Function\n",
    "                Sampler to be used in optuna. Default = TPESampler()\n",
    "            optuna_direction : str\n",
    "                Direction of optimization. Default = 'maximize'\n",
    "                Available Directions:\n",
    "                    maximize : Maximize\n",
    "                    minimize : Minimize\n",
    "            optuna_n_trials : int\n",
    "                No. of trials for optuna. Default = 100\n",
    "            optuna_metric: str\n",
    "                Metric to be used in optuna. Default = 'r2'\n",
    "        Returns:\n",
    "\n",
    "            Dict Containing Name of Regressor, Its K-Fold Cross Validated Accuracy, RMSE, Prediction set\n",
    "\n",
    "            Dataframe containing all the models and their accuracies when predictor is 'all'\n",
    "\n",
    "        Example:\n",
    "\n",
    "            from luciferml.supervised.regression import Regression\n",
    "\n",
    "            dataset = pd.read_excel('examples\\Folds5x2_pp.xlsx')\n",
    "\n",
    "            X = dataset.iloc[:, :-1]\n",
    "\n",
    "            y = dataset.iloc[:, -1]\n",
    "\n",
    "            regressor = Regression(predictor = 'lin')\n",
    "\n",
    "            regressor.fit(X, y)\n",
    "\n",
    "            result = regressor.result()\n",
    "\n",
    "        \"\"\"\n",
    "        self.preprocess = PreProcesser()\n",
    "        if type(predictor) == list:\n",
    "            if not \"all\" in predictor:\n",
    "                self.predictor = predictor[0] if len(predictor) == 1 else predictor\n",
    "            else:\n",
    "                self.predictor = predictor\n",
    "        else:\n",
    "            self.predictor = predictor\n",
    "        bool_pred, pred = pred_check(predictor, pred_type=\"regression\")\n",
    "        if not bool_pred:\n",
    "            raise ValueError(unsupported_pred_warning.format(pred))\n",
    "        self.original_predictor = predictor\n",
    "        self.params = params\n",
    "        self.tune = tune\n",
    "        self.test_size = test_size\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.pca_kernel = pca_kernel\n",
    "        self.n_components_lda = n_components_lda\n",
    "        self.lda = lda\n",
    "        self.pca = pca\n",
    "        self.n_components_pca = n_components_pca\n",
    "        self.loss = loss\n",
    "        self.validation_split = validation_split\n",
    "        self.rerun = False\n",
    "        self.smote = smote\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.verbose = verbose\n",
    "        self.exclude_models = exclude_models\n",
    "        self.sampler = optuna_sampler\n",
    "        self.direction = optuna_direction\n",
    "        self.n_trials = optuna_n_trials\n",
    "        self.metric = optuna_metric\n",
    "\n",
    "        self.accuracy_scores = {}\n",
    "        self.reg_result = {}\n",
    "        self.rm_squared_error = 0\n",
    "        self.accuracy = 0\n",
    "        self.y_pred = []\n",
    "        self.kfold_accuracy = 0\n",
    "        self.regressor_name = \"\"\n",
    "        self.sc = 0\n",
    "\n",
    "        self.kfoldacc = []\n",
    "        self.acc = []\n",
    "        self.mae = []\n",
    "        self.rmse = []\n",
    "        self.bestacc = []\n",
    "        self.bestparams = []\n",
    "        self.regressor_model = []\n",
    "        self.tuned_trained_model = []\n",
    "        self.best_regressor_path = \"\"\n",
    "        self.scaler_path = \"\"\n",
    "        self.result_df = pd.DataFrame(index=None)\n",
    "        self.regressors = copy.deepcopy(regressors)\n",
    "        for i in self.exclude_models:\n",
    "            self.regressors.pop(i)\n",
    "        self.best_regressor = \"First Run the Predictor in All mode\"\n",
    "        self.objective = None\n",
    "        self.pred_mode = \"\"\n",
    "        self.model_to_predict = None\n",
    "\n",
    "        if path != None:\n",
    "            try:\n",
    "                self.regressor, self.sc = self.__load(path)\n",
    "            except Exception as e:\n",
    "                print(Fore.RED + e)\n",
    "                print(Fore.RED + \"Model not found\")\n",
    "        if not self.verbose:\n",
    "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        \"\"\"[Takes Features and Labels and Encodes Categorical Data then Applies SMOTE , Splits the features and labels in training and validation sets with test_size = .2\n",
    "        scales X_train, X_val using StandardScaler.\n",
    "        Fits model on training set and predicts results, Finds R2 Score and mean square error\n",
    "        finds accuracy of model applies K-Fold Cross Validation\n",
    "        and stores its accuracies in a dictionary containing Model name as Key and accuracies as values and returns it\n",
    "        Applies GridSearch Cross Validation and gives best params out from param list.]\n",
    "\n",
    "        Args:\n",
    "\n",
    "            features ([Pandas DataFrame]): [DataFrame containing Features]\n",
    "            labels ([Pandas DataFrame]): [DataFrame containing Labels]\n",
    "        \"\"\"\n",
    "\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "        # Time Function ---------------------------------------------------------------------\n",
    "\n",
    "        self.start = time.time()\n",
    "        print(Fore.MAGENTA + intro, \"\\n\")\n",
    "        print(Fore.GREEN + \"Started LuciferML [\", \"\\u2713\", \"]\\n\")\n",
    "        if not self.rerun:\n",
    "            # CHECKUP ---------------------------------------------------------------------\n",
    "            if not isinstance(self.features, pd.DataFrame) and not isinstance(\n",
    "                self.labels, pd.Series\n",
    "            ):\n",
    "                print(\n",
    "                    Fore.RED\n",
    "                    + \"TypeError: This Function take features as Pandas Dataframe and labels as Pandas Series. Please check your implementation.\\n\"\n",
    "                )\n",
    "                end = time.time()\n",
    "                print(self.end - self.start)\n",
    "                return\n",
    "            print(Fore.YELLOW + \"Preprocessing Started [*]\\n\")\n",
    "\n",
    "            self.features, self.labels = self.preprocess.encoder(\n",
    "                self.features, self.labels\n",
    "            )\n",
    "            self.features, self.labels = sparse_check(self.features, self.labels)\n",
    "            (\n",
    "                self.X_train,\n",
    "                self.X_val,\n",
    "                self.y_train,\n",
    "                self.y_val,\n",
    "                self.sc,\n",
    "            ) = self.preprocess.data_preprocess(\n",
    "                self.features,\n",
    "                self.labels,\n",
    "                self.test_size,\n",
    "                self.random_state,\n",
    "                self.smote,\n",
    "                self.k_neighbors,\n",
    "            )\n",
    "            self.X_train, self.X_val = self.preprocess.dimensionality_reduction(\n",
    "                self.lda,\n",
    "                self.pca,\n",
    "                self.X_train,\n",
    "                self.X_val,\n",
    "                self.y_train,\n",
    "                self.n_components_lda,\n",
    "                self.n_components_pca,\n",
    "                self.pca_kernel,\n",
    "                self.start,\n",
    "            )\n",
    "\n",
    "        print(Fore.GREEN + \"Preprocessing Done [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        if self.original_predictor == \"all\" or type(self.predictor) == list:\n",
    "            if 'all' in self.predictor and type(self.predictor)==list:\n",
    "                self.predictor.remove('all')\n",
    "            self.model_to_predict = (\n",
    "                self.predictor if len(self.predictor) > 1 and type(self.predictor) == list else self.regressors\n",
    "            )\n",
    "            self.result_df[\"Name\"] = (\n",
    "                list(self.regressors[i] for i in self.predictor)\n",
    "                if type(self.predictor) == list and len(self.predictor) > 1\n",
    "                else list(self.regressors.values())\n",
    "            )\n",
    "            self.pred_mode = \"all\" if type(self.predictor) == list and len(\n",
    "                self.predictor) > 1 else \"single\"\n",
    "            self.__fitall()\n",
    "            return\n",
    "        self.regressor, self.objective = regression_predictor(\n",
    "            self.predictor,\n",
    "            self.params,\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            self.cv_folds,\n",
    "            self.random_state,\n",
    "            self.metric,\n",
    "            verbose=self.verbose,\n",
    "        )\n",
    "        try:\n",
    "            self.regressor.fit(self.X_train, self.y_train)\n",
    "        except Exception as error:\n",
    "            print(Fore.RED + \"Regressor Build Failed with error: \", error, \"\\n\")\n",
    "        finally:\n",
    "            print(Fore.GREEN + \"Model Trained Successfully [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        try:\n",
    "            print(Fore.YELLOW + \"Evaluating Model Performance [*]\\n\")\n",
    "            self.y_pred = self.regressor.predict(self.X_val)\n",
    "            self.accuracy = r2_score(self.y_val, self.y_pred)\n",
    "            self.m_absolute_error = mean_absolute_error(self.y_val, self.y_pred)\n",
    "            self.rm_squared_error = mean_squared_error(\n",
    "                self.y_val, self.y_pred, squared=False\n",
    "            )\n",
    "            print(\n",
    "                Fore.CYAN\n",
    "                + \"        Validation R2 Score is {:.2f} %\".format(self.accuracy * 100)\n",
    "            )\n",
    "            print(\n",
    "                Fore.CYAN + \"        Validation Mean Absolute Error is :\",\n",
    "                self.m_absolute_error,\n",
    "            )\n",
    "            print(\n",
    "                Fore.CYAN + \"        Validation Root Mean Squared Error is :\",\n",
    "                self.rm_squared_error,\n",
    "            )\n",
    "            self.regressor_name, self.kfold_accuracy = kfold(\n",
    "                self.regressor,\n",
    "                self.predictor,\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                self.cv_folds,\n",
    "                isReg=True,\n",
    "            )\n",
    "        except Exception as error:\n",
    "            print(Fore.RED + \"Model Evaluation Failed with error: \", error, \"\\n\")\n",
    "        finally:\n",
    "            print(Fore.GREEN + \"Model Evaluation Completed [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        if not self.predictor == \"nb\" and self.tune:\n",
    "            self.__tuner()\n",
    "\n",
    "        print(Fore.GREEN + \"Completed LuciferML Run [\", \"\\u2713\", \"]\\n\")\n",
    "        self.end = time.time()\n",
    "        final_time = self.end - self.start\n",
    "        print(Fore.BLUE + \"Time Elapsed : \", f\"{final_time:.2f}\", \"seconds \\n\")\n",
    "\n",
    "    def __fitall(self):\n",
    "        print(Fore.YELLOW + \"Training LuciferML [*]\\n\")\n",
    "        if self.params != {}:\n",
    "            warnings.warn(params_use_warning, UserWarning)\n",
    "            self.params = {}\n",
    "        for _, self.predictor in enumerate(self.model_to_predict):\n",
    "            if not self.predictor in self.exclude_models:\n",
    "                (self.regressor, self.objective,) = regression_predictor(\n",
    "                    self.predictor,\n",
    "                    self.params,\n",
    "                    self.X_train,\n",
    "                    self.y_train,\n",
    "                    self.cv_folds,\n",
    "                    self.random_state,\n",
    "                    self.metric,\n",
    "                    mode=\"multi\",\n",
    "                    verbose=self.verbose,\n",
    "                )\n",
    "                try:\n",
    "                    self.regressor.fit(self.X_train, self.y_train)\n",
    "                except Exception as error:\n",
    "                    print(\n",
    "                        Fore.RED + regressors[self.predictor],\n",
    "                        \"Model Train Failed with error: \",\n",
    "                        error,\n",
    "                        \"\\n\",\n",
    "                    )\n",
    "                try:\n",
    "                    self.y_pred = self.regressor.predict(self.X_val)\n",
    "                    self.accuracy = r2_score(self.y_val, self.y_pred)\n",
    "                    self.m_absolute_error = mean_absolute_error(self.y_val, self.y_pred)\n",
    "                    self.rm_squared_error = mean_squared_error(\n",
    "                        self.y_val, self.y_pred, squared=False\n",
    "                    )\n",
    "                    self.acc.append(self.accuracy * 100)\n",
    "                    self.rmse.append(self.rm_squared_error)\n",
    "                    self.mae.append(self.m_absolute_error)\n",
    "                    self.regressor_name, self.kfold_accuracy = kfold(\n",
    "                        self.regressor,\n",
    "                        self.predictor,\n",
    "                        self.X_train,\n",
    "                        self.y_train,\n",
    "                        self.cv_folds,\n",
    "                        all_mode=True,\n",
    "                        isReg=True,\n",
    "                    )\n",
    "                    self.kfoldacc.append(self.kfold_accuracy)\n",
    "                    self.regressor_model.append(self.regressor)\n",
    "                except Exception as error:\n",
    "                    print(\n",
    "                        Fore.RED + regressors[self.predictor],\n",
    "                        \"Evaluation Failed with error: \",\n",
    "                        error,\n",
    "                        \"\\n\",\n",
    "                    )\n",
    "\n",
    "                if self.tune:\n",
    "                    self.__tuner(all_mode=True, single_mode=False)\n",
    "                if self.predictor == \"nb\":\n",
    "                    self.best_params = \"\"\n",
    "                    self.best_accuracy = self.kfold_accuracy\n",
    "        self.result_df[\"R2 Score\"] = self.acc\n",
    "        self.result_df[\"Mean Absolute Error\"] = self.mae\n",
    "        self.result_df[\"Root Mean Squared Error\"] = self.rmse\n",
    "        self.result_df[\"KFold Accuracy\"] = self.kfoldacc\n",
    "        self.result_df[\"Model\"] = self.regressor_model\n",
    "\n",
    "        if self.tune:\n",
    "            self.result_df[\"Best Parameters\"] = self.bestparams\n",
    "            self.result_df[\"Best Accuracy\"] = self.bestacc\n",
    "            self.result_df[\"Trained Model\"] = self.tuned_trained_model\n",
    "            self.best_regressor = Best(\n",
    "                self.result_df.loc[self.result_df[\"Best Accuracy\"].idxmax()],\n",
    "                self.tune,\n",
    "                isReg=True,\n",
    "            )\n",
    "        else:\n",
    "            self.best_regressor = Best(\n",
    "                self.result_df.loc[self.result_df[\"KFold Accuracy\"].idxmax()],\n",
    "                self.tune,\n",
    "                isReg=True,\n",
    "            )\n",
    "        print(Fore.GREEN + \"Training Done [\", \"\\u2713\", \"]\\n\")\n",
    "        print(Fore.CYAN + \"Results Below\\n\")\n",
    "        display(self.result_df)\n",
    "        print(Fore.GREEN + \"\\nCompleted LuciferML Run [\", \"\\u2713\", \"]\\n\")\n",
    "        if len(self.model_to_predict) > 1:\n",
    "            self.best_regressor_path, self.scaler_path = self.save(\n",
    "                best=True, model=self.best_regressor.model, scaler=self.sc\n",
    "            )\n",
    "            print(\n",
    "                Fore.CYAN\n",
    "                + \"Saved Best Model to {} and its scaler to {}\".format(\n",
    "                    self.best_regressor_path, self.scaler_path\n",
    "                ),\n",
    "                \"\\n\",\n",
    "            )\n",
    "        self.end = time.time()\n",
    "        final_time = self.end - self.start\n",
    "        print(Fore.BLUE + \"Time Elapsed : \", f\"{final_time:.2f}\", \"seconds \\n\")\n",
    "        return\n",
    "\n",
    "    def __tuner(self, all_mode=False, single_mode=True):\n",
    "        if not all_mode or single_mode:\n",
    "            print(Fore.YELLOW + \"Tuning Started [*]\\n\")\n",
    "        if not self.predictor == \"nb\":\n",
    "            (\n",
    "                self.best_params,\n",
    "                self.best_accuracy,\n",
    "                self.best_trained_model,\n",
    "            ) = luciferml_tuner(\n",
    "                self.predictor,\n",
    "                self.objective,\n",
    "                self.n_trials,\n",
    "                self.sampler,\n",
    "                self.direction,\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                self.cv_folds,\n",
    "                self.random_state,\n",
    "                self.metric,\n",
    "                all_mode=all_mode,\n",
    "                isReg=True,\n",
    "            )\n",
    "        if self.predictor == \"nb\":\n",
    "            self.best_params = \"Not Applicable\"\n",
    "            self.best_accuracy = 0\n",
    "        self.bestparams.append(self.best_params)\n",
    "        self.bestacc.append(self.best_accuracy * 100)\n",
    "        self.tuned_trained_model.append(self.best_trained_model)\n",
    "        if not all_mode or single_mode:\n",
    "            print(Fore.GREEN + \"Tuning Done [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"[Makes a dictionary containing Regressor Name, K-Fold CV Accuracy, RMSE, Prediction set.]\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            [dict]: [Dictionary containing :\n",
    "                        - \"Regressor\" - Regressor Name\n",
    "                        - \"Accuracy\" - KFold CV Accuracy\n",
    "                        - \"RMSE\" - Root Mean Square\n",
    "                        - \"YPred\" - Array for Prediction set\n",
    "                        ]\n",
    "            [dataframe] : [Dataset containing accuracy and best_params\n",
    "                            for all predictors only when predictor = 'all' is used\n",
    "                            ]\n",
    "        \"\"\"\n",
    "        if not self.pred_mode == \"all\":\n",
    "            self.reg_result[\"Regressor\"] = self.regressor_name\n",
    "            self.reg_result[\"Accuracy\"] = self.kfold_accuracy\n",
    "            self.reg_result[\"RMSE\"] = self.rm_squared_error\n",
    "            self.reg_result[\"YPred\"] = self.y_pred\n",
    "\n",
    "            return self.reg_result\n",
    "        if self.pred_mode == \"all\":\n",
    "            return self.result_df\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"[Takes test set and returns predictions for that test set]\n",
    "\n",
    "        Args:\n",
    "            X_test ([Array]): [Array Containing Test Set]\n",
    "\n",
    "        Returns:\n",
    "            [Array]: [Predicted set for given test set]\n",
    "        \"\"\"\n",
    "        if not self.pred_mode == \"all\":\n",
    "            X_test = np.array(X_test)\n",
    "            if X_test.ndim == 1:\n",
    "                X_test = X_test.reshape(1, -1)\n",
    "\n",
    "            y_test = self.regressor.predict(self.sc.transform(X_test))\n",
    "\n",
    "            return y_test\n",
    "        if self.pred_mode == \"all\":\n",
    "            raise TypeError(\"Predict is only applicable on single predictor\")\n",
    "\n",
    "    def save(self, path=None, best=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Saves the model and its scaler to a file provided with a path.\n",
    "        If no path is provided will create a directory named\n",
    "        lucifer_ml_info/models/ and lucifer_ml_info/scaler/ in current working directory\n",
    "\n",
    "        Args:\n",
    "\n",
    "            path ([list]): [List containing path to save the model and scaler.]\n",
    "                Example: path = [\"model.pkl\", \"scaler.pkl\"]\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Path to the saved model and its scaler.\n",
    "        \"\"\"\n",
    "        if not type(path) == list and path != None:\n",
    "            raise TypeError(\"Path must be a list\")\n",
    "        if self.pred_mode == \"all\" and best == False:\n",
    "            raise TypeError(\"Cannot save model for all predictors\")\n",
    "        dir_path_model = path[0] if path else \"lucifer_ml_info/models/regression/\"\n",
    "        dir_path_scaler = path[1] if path else \"lucifer_ml_info/scalers/regression/\"\n",
    "        model_name = regressors[self.predictor].replace(\" \", \"_\")\n",
    "        if best:\n",
    "            dir_path_model = \"lucifer_ml_info/best/regression/models/\"\n",
    "            dir_path_scaler = \"lucifer_ml_info/best/regression/scalers/\"\n",
    "            model_name = self.best_regressor.name.replace(\" \", \"_\")\n",
    "        os.makedirs(dir_path_model, exist_ok=True)\n",
    "        os.makedirs(dir_path_scaler, exist_ok=True)\n",
    "        timestamp = str(int(time.time()))\n",
    "        path_model = dir_path_model + model_name + \"_\" + timestamp + \".pkl\"\n",
    "        path_scaler = (\n",
    "            dir_path_scaler + model_name + \"_\" + \"Scaler\" + \"_\" + timestamp + \".pkl\"\n",
    "        )\n",
    "        if (\n",
    "            not kwargs.get(\"model\")\n",
    "            and not kwargs.get(\"best\")\n",
    "            and not kwargs.get(\"scaler\")\n",
    "        ):\n",
    "            dump(self.regressor, open(path_model, \"wb\"))\n",
    "            dump(self.sc, open(path_scaler, \"wb\"))\n",
    "        else:\n",
    "            dump(kwargs.get(\"model\"), open(path_model, \"wb\"))\n",
    "            dump(kwargs.get(\"scaler\"), open(path_scaler, \"wb\"))\n",
    "        if not best:\n",
    "            print(\"Model Saved at {} and Scaler at {}\".format(path_model, path_scaler))\n",
    "        return path_model, path_scaler\n",
    "\n",
    "    def __load(self, path=None):\n",
    "        \"\"\"\n",
    "        Loads model and scaler from the specified path\n",
    "\n",
    "        Args:\n",
    "\n",
    "            path ([list]): [List containing path to load the model and scaler.]\n",
    "                Example: path = [\"model.pkl\", \"scaler.pkl\"]\n",
    "\n",
    "        Returns:\n",
    "            [Model] : [Loaded model]\n",
    "            [Scaler] : [Loaded scaler]\n",
    "        \"\"\"\n",
    "        model_path = path[0] if path[0] else None\n",
    "        scaler_path = path[1] if path[1] else None\n",
    "        if not \".pkl\" in model_path and not model_path == None:\n",
    "            raise TypeError(\n",
    "                \"[Error] Model Filetype not supported. Please use .pkl type \"\n",
    "            )\n",
    "        if not \".pkl\" in scaler_path and not scaler_path == None:\n",
    "            raise TypeError(\n",
    "                \"[Error] Scaler Filetype not supported. Please use .pkl type \"\n",
    "            )\n",
    "        if model_path != None and scaler_path != None:\n",
    "            model = load(open(model_path, \"rb\"))\n",
    "            scaler = load(open(scaler_path, \"rb\"))\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + \"[Info] Model and Scaler Loaded from {} and {}\".format(\n",
    "                    model_path, scaler_path\n",
    "                )\n",
    "            )\n",
    "            return model, scaler\n",
    "        elif model_path != None and scaler_path == None:\n",
    "            model = load(open(model_path, \"rb\"))\n",
    "            print(Fore.GREEN + \"[Info] Model Loaded from {}\".format(model_path))\n",
    "            return model\n",
    "        elif model_path == None and scaler_path != None:\n",
    "            scaler = load(open(scaler_path, \"rb\"))\n",
    "            print(Fore.GREEN + \"[Info] Scaler Loaded from {}\".format(scaler_path))\n",
    "            return scaler\n",
    "        else:\n",
    "            raise ValueError(\"No path specified.Please provide actual path\\n\")\n",
    "\n",
    "    def imp_features(self, extensive=False, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns the importance features of the dataset\n",
    "\n",
    "        Args:\n",
    "\n",
    "            extensive (bool): [If True shows the importance of all features exitensively and will take more time] [default = False]\n",
    "            **args: [Additional arguments]\n",
    "            **kwargs: [Additional keyword arguments]\n",
    "        \"\"\"\n",
    "        if self.original_predictor == \"all\":\n",
    "            raise TypeError(\n",
    "                \"[Error] This method is only applicable on single predictor\"\n",
    "            )\n",
    "        if not extensive:\n",
    "            self.preprocess.permutational_feature_imp(\n",
    "                self.features, self.X_train, self.y_train, model=self.regressor\n",
    "            )\n",
    "        if extensive:\n",
    "            self.preprocess.shap_feature_imp(\n",
    "                self.features, self.X_train, model=self.regressor, *args, **kwargs\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
