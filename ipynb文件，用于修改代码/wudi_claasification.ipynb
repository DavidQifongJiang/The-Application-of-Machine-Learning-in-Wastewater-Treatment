{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790ee57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from re import S\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Ericd\\OneDrive\\Desktop\\wudimoxing\")\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from joblib import dump, load\n",
    "from wudi_pic import Best\n",
    "from wudi_best import *\n",
    "from wudi_predictor import classification_predictor\n",
    "from wudi_preprocessor import PreProcesser\n",
    "from wudi_model_tuner import wudimodel_tuner\n",
    "from wudi_validator import *\n",
    "from optuna.samplers._tpe.sampler import TPESampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c72d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "``multivariate`` option is an experimental feature. The interface can change in the future.\n"
     ]
    }
   ],
   "source": [
    "class Classification:\n",
    "    def __init__(\n",
    "        self,\n",
    "        predictor=[\"lr\"],\n",
    "        params={},\n",
    "        tune=False,\n",
    "        test_size=0.2,\n",
    "        cv_folds=10,\n",
    "        random_state=42,\n",
    "        pca_kernel=\"linear\",\n",
    "        n_components_lda=1,\n",
    "        lda=\"n\",\n",
    "        pca=\"n\",\n",
    "        n_components_pca=2,\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "        ],\n",
    "        loss=\"binary_crossentropy\",\n",
    "        validation_split=0.20,\n",
    "        tune_mode=1,\n",
    "        smote=\"n\",\n",
    "        k_neighbors=1,\n",
    "        verbose=False,\n",
    "        exclude_models=[],\n",
    "        path=None,\n",
    "        optuna_sampler=TPESampler(multivariate=True),\n",
    "        optuna_direction=\"maximize\",\n",
    "        optuna_n_trials=100,\n",
    "        optuna_metric=\"accuracy\",\n",
    "        lgbm_objective=\"binary\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Encode Categorical Data then Applies SMOTE , Splits the features and labels in training and validation sets with test_size = .2 , scales self.X_train, self.X_val using StandardScaler.\\n\n",
    "        Fits every model on training set and predicts results find and plots Confusion Matrix,\\n\n",
    "        finds accuracy of model applies K-Fold Cross Validation\\n\n",
    "        and stores accuracy in variable name accuracy and model name in self.classifier name and returns both as a tuple.\\n\n",
    "        Applies HyperParam Tuning and gives best params and accuracy.\\n\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "            features : array\n",
    "                        features array\n",
    "            lables : array\n",
    "                        labels array\n",
    "            predictor : list\n",
    "                        Predicting model to be used\n",
    "                        Default ['lr']  - Logistic Regression\\n\n",
    "                        Available Predictors:\n",
    "                                lr - Logisitic Regression\\n\n",
    "                                sgd - Stochastic Gradient Descent Classifier\\n\n",
    "                                perc - Perceptron\\n\n",
    "                                pass - Passive Aggressive Classifier\\n\n",
    "                                ridg - Ridge Classifier\\n\n",
    "                                svm -SupportVector Machine\\n\n",
    "                                knn - K-Nearest Neighbours\\n\n",
    "                                nb - GaussianNaive bayes\\n\n",
    "                                rfc- Random Forest self.Classifier\\n\n",
    "                                gbc - Gradient Boosting Classifier\\n\n",
    "                                ada - AdaBoost Classifier\\n\n",
    "                                bag - Bagging Classifier\\n\n",
    "                                extc - Extra Trees Classifier\\n\n",
    "                                lgbm - LightGBM Classifier\\n\n",
    "                                cat - CatBoost Classifier\\n\n",
    "                                xgb- XGBoost self.Classifier\\n\n",
    "                                ann - MultiLayer Perceptron Classifier\\n\n",
    "                                all - Applies all above classifiers\\n\n",
    "                                \n",
    "            params : dict\n",
    "                        contains parameters for model\n",
    "            tune : boolean\n",
    "                    when True Applies GridSearch CrossValidation\n",
    "                    Default is False\n",
    "            test_size: float or int, default=.2\n",
    "                        If float, should be between 0.0 and 1.0 and represent\n",
    "                        the proportion of the dataset to include in\n",
    "                        the test split.\n",
    "                        If int, represents the absolute number of test samples.\n",
    "            cv_folds : int\n",
    "                    No. of cross validation folds. Default = 10\n",
    "            pca : str\n",
    "                if 'y' will apply PCA on Train and Validation set. Default = 'n'\n",
    "            lda : str\n",
    "                if 'y' will apply LDA on Train and Validation set. Default = 'n'\n",
    "            pca_kernel : str\n",
    "                    Kernel to be use in PCA. Default = 'linear'\n",
    "            n_components_lda : int\n",
    "                    No. of components for LDA. Default = 1\n",
    "            n_components_pca : int\n",
    "                    No. of components for PCA. Default = 2\n",
    "            loss : str\n",
    "                    loss method for ann. Default = 'binary_crossentropy'\n",
    "                    rate for dropout layer. Default = 0\n",
    "            smote : str,\n",
    "                Whether to apply SMOTE. Default = 'y'\n",
    "            k_neighbors : int\n",
    "                No. of neighbours for SMOTE. Default = 1\n",
    "            verbose : boolean\n",
    "                Verbosity of models. Default = False\n",
    "            exclude_models : list\n",
    "                List of models to be excluded when using predictor = 'all' . Default = []\n",
    "            path : list\n",
    "                List containing path to saved model and scaler. Default = None\n",
    "                Example: [model.pkl, scaler.pkl]\n",
    "            random_state : int\n",
    "                Random random_state for reproducibility. Default = 42\n",
    "            optuna_sampler : Function\n",
    "                Sampler to be used in optuna. Default = TPESampler()\n",
    "            optuna_direction : str\n",
    "                Direction of optimization. Default = 'maximize'\n",
    "                Available Directions:\n",
    "                    maximize : Maximize\n",
    "                    minimize : Minimize\n",
    "            optuna_n_trials : int\n",
    "                No. of trials for optuna. Default = 100\n",
    "            optuna_metric: str\n",
    "                Metric to be used in optuna. Default = 'r2'\n",
    "            lgbm_objective : str\n",
    "                Objective for lgbm classifier. Default = 'binary'\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Dict Containing Name of Classifiers, Its K-Fold Cross Validated Accuracy and Prediction set\n",
    "\n",
    "            Dataframe containing all the models and their accuracies when predictor is 'all'\n",
    "\n",
    "        Example:\n",
    "\n",
    "            from luciferml.supervised.classification import Classification\n",
    "\n",
    "            dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "\n",
    "            X = dataset.iloc[:, :-1]\n",
    "\n",
    "            y = dataset.iloc[:, -1]\n",
    "\n",
    "            classifier = Classification(predictor = 'lr')\n",
    "\n",
    "            classifier.fit(X, y)\n",
    "\n",
    "            result = classifier.result()\n",
    "\n",
    "        \"\"\"\n",
    "        self.preprocess = PreProcesser()\n",
    "        if type(predictor) == list:\n",
    "            if not \"all\" in predictor:\n",
    "                self.predictor = predictor[0] if len(\n",
    "                    predictor) == 1 else predictor\n",
    "            else:\n",
    "                self.predictor = predictor\n",
    "        else:\n",
    "            self.predictor = predictor\n",
    "        bool_pred, pred = pred_check(predictor, pred_type=\"classification\")\n",
    "        if not bool_pred:\n",
    "            raise ValueError(unsupported_pred_warning.format(pred))\n",
    "        self.original_predictor = predictor\n",
    "        self.params = params\n",
    "        self.tune = tune\n",
    "        self.test_size = test_size\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.pca_kernel = pca_kernel\n",
    "        self.n_components_lda = n_components_lda\n",
    "        self.lda = lda\n",
    "        self.pca = pca\n",
    "        self.n_components_pca = n_components_pca\n",
    "        self.metrics = metrics\n",
    "        self.loss = loss\n",
    "        self.validation_split = validation_split\n",
    "        self.tune_mode = tune_mode\n",
    "        self.rerun = False\n",
    "        self.smote = smote\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.verbose = verbose\n",
    "        self.exclude_models = exclude_models\n",
    "        self.sampler = optuna_sampler\n",
    "        self.direction = optuna_direction\n",
    "        self.n_trials = optuna_n_trials\n",
    "        self.metric = optuna_metric\n",
    "        self.lgbm_objective = lgbm_objective\n",
    "\n",
    "        self.accuracy_scores = {}\n",
    "        self.reg_result = {}\n",
    "        self.accuracy = 0\n",
    "        self.y_pred = []\n",
    "        self.kfold_accuracy = 0\n",
    "        self.classifier_name = \"\"\n",
    "        self.sc = 0\n",
    "\n",
    "        self.kfoldacc = []\n",
    "        self.acc = []\n",
    "        self.bestacc = []\n",
    "        self.bestparams = []\n",
    "        self.tuned_trained_model = []\n",
    "        self.best_classifier_path = \"\"\n",
    "        self.scaler_path = \"\"\n",
    "        self.classifier_model = []\n",
    "        self.result_df = pd.DataFrame(index=None)\n",
    "        self.classifiers = copy.deepcopy(classifiers)\n",
    "        for i in self.exclude_models:\n",
    "            self.classifiers.pop(i)\n",
    "        self.best_classifier = \"First Run the Predictor in All mode\"\n",
    "        self.objective = None\n",
    "        self.pred_mode = \"\"\n",
    "        self.model_to_predict = []\n",
    "\n",
    "        if path != None:\n",
    "            try:\n",
    "                self.classifier, self.sc = self.__load(path)\n",
    "            except Exception as e:\n",
    "                print(Fore.RED + e)\n",
    "                print(Fore.RED + \"Model not found\")\n",
    "        if not self.verbose:\n",
    "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        \"\"\"[Takes Features and Labels and Encodes Categorical Data then Applies SMOTE , Splits the features and labels in training and validation sets with test_size = .2\n",
    "        scales X_train, self.X_val using StandardScaler.\n",
    "        Fits every model on training set and predicts results,\n",
    "        finds accuracy of model applies K-Fold Cross Validation\n",
    "        and stores its accuracies in a dictionary containing Model name as Key and accuracies as values and returns it\n",
    "        Applies GridSearch Cross Validation and gives best params out from param list.]\n",
    "\n",
    "        Args:\n",
    "            features ([Pandas DataFrame]): [DataFrame containing Features]\n",
    "            labels ([Pandas DataFrame]): [DataFrame containing Labels]\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        # Time Function ---------------------------------------------------------------------\n",
    "\n",
    "        self.start = time.time()\n",
    "        print(Fore.MAGENTA + intro, \"\\n\")\n",
    "        print(Fore.GREEN + \"Started LuciferML [\", \"\\u2713\", \"]\\n\")\n",
    "        if not self.rerun:\n",
    "            # CHECKUP ---------------------------------------------------------------------\n",
    "            if not isinstance(self.features, pd.DataFrame) and not isinstance(\n",
    "                self.labels, pd.Series\n",
    "            ):\n",
    "                print(\n",
    "                    Fore.RED\n",
    "                    + \"TypeError: This Function take features as Pandas Dataframe and labels as Pandas Series. Please check your implementation.\\n\"\n",
    "                )\n",
    "                self.end = time.time()\n",
    "                print(self.end - self.start)\n",
    "                return\n",
    "\n",
    "            print(Fore.YELLOW + \"Preprocessing Started [*]\\n\")\n",
    "            self.features, self.labels = self.preprocess.encoder(\n",
    "                self.features, self.labels\n",
    "            )\n",
    "\n",
    "            self.features, self.labels = sparse_check(self.features, self.labels)\n",
    "\n",
    "            (\n",
    "                self.X_train,\n",
    "                self.X_val,\n",
    "                self.y_train,\n",
    "                self.y_val,\n",
    "                self.sc,\n",
    "            ) = self.preprocess.data_preprocess(\n",
    "                self.features,\n",
    "                self.labels,\n",
    "                self.test_size,\n",
    "                self.random_state,\n",
    "                self.smote,\n",
    "                self.k_neighbors,\n",
    "            )\n",
    "\n",
    "            self.X_train, self.X_val = self.preprocess.dimensionality_reduction(\n",
    "                self.lda,\n",
    "                self.pca,\n",
    "                self.X_train,\n",
    "                self.X_val,\n",
    "                self.y_train,\n",
    "                self.n_components_lda,\n",
    "                self.n_components_pca,\n",
    "                self.pca_kernel,\n",
    "                self.start,\n",
    "            )\n",
    "\n",
    "        print(Fore.GREEN + \"Preprocessing Done [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        if self.original_predictor == \"all\" or type(self.predictor) == list:\n",
    "            if 'all' in self.predictor and type(self.predictor)==list:\n",
    "                self.predictor.remove('all')\n",
    "            self.model_to_predict = (\n",
    "                self.predictor if len(self.predictor) > 1 and type(self.predictor) == list else self.classifiers\n",
    "            )\n",
    "            \n",
    "            self.result_df[\"Name\"] = (\n",
    "                list(self.classifiers[i] for i in self.predictor)\n",
    "                if type(self.predictor) == list and len(self.predictor) > 1\n",
    "                else list(self.classifiers.values())\n",
    "            )\n",
    "            self.pred_mode = \"all\" if len(self.predictor) > 1 and type(\n",
    "                self.predictor) == list else \"single\"\n",
    "            self.__fitall()\n",
    "            return\n",
    "\n",
    "        self.classifier, self.objective = classification_predictor(\n",
    "            self.predictor,\n",
    "            self.params,\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            self.cv_folds,\n",
    "            self.random_state,\n",
    "            self.metric,\n",
    "            verbose=self.verbose,\n",
    "            lgbm_objective=self.lgbm_objective,\n",
    "        )\n",
    "        try:\n",
    "            self.classifier.fit(self.X_train, self.y_train)\n",
    "        except Exception as error:\n",
    "            print(Fore.RED + \"Classifier Build Failed with error: \", error, \"\\n\")\n",
    "        finally:\n",
    "            print(Fore.GREEN + \"Model Trained Successfully [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        try:\n",
    "            print(Fore.YELLOW + \"Evaluating Model Performance [*]\\n\")\n",
    "            self.y_pred = self.classifier.predict(self.X_val)\n",
    "            if self.predictor == \"ann\":\n",
    "                self.y_pred = (self.y_pred > 0.5).astype(\"int32\")\n",
    "            self.accuracy = accuracy_score(self.y_val, self.y_pred)\n",
    "            print(Fore.CYAN + \"        Validation Accuracy is : {:.2f} %\".format(self.accuracy * 100))\n",
    "            self.classifier_name, self.kfold_accuracy = kfold(\n",
    "                self.classifier,\n",
    "                self.predictor,\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                self.cv_folds,\n",
    "            )\n",
    "            self.preprocess.confusion_matrix(self.y_pred, self.y_val)\n",
    "        except Exception as error:\n",
    "            print(Fore.RED + \"Model Evaluation Failed with error: \", error, \"\\n\")\n",
    "        finally:\n",
    "            print(Fore.GREEN + \"Model Evaluation Completed [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "        if not self.predictor == \"nb\" and self.tune:\n",
    "            self.__tuner()\n",
    "\n",
    "        print(Fore.GREEN + \"Completed LuciferML Run [\", \"\\u2713\", \"]\\n\")\n",
    "        self.end = time.time()\n",
    "        final_time = self.end - self.start\n",
    "        print(Fore.BLUE + \"Time Elapsed : \", f\"{final_time:.2f}\", \"seconds \\n\")\n",
    "\n",
    "    def __fitall(self):\n",
    "        print(Fore.YELLOW + \"Training LuciferML [*]\\n\")\n",
    "        if self.params != {}:\n",
    "            warnings.warn(params_use_warning, UserWarning)\n",
    "            self.params = {}\n",
    "        for _, self.predictor in enumerate(self.model_to_predict):\n",
    "            if not self.predictor in self.exclude_models:\n",
    "                try:\n",
    "                    self.classifier, self.objective = classification_predictor(\n",
    "                    self.predictor,\n",
    "                    self.params,\n",
    "                    self.X_train,\n",
    "                    self.y_train,\n",
    "                    self.cv_folds,\n",
    "                    self.random_state,\n",
    "                    self.metric,\n",
    "                    mode=\"multi\",\n",
    "                    verbose=self.verbose,\n",
    "                    lgbm_objective=self.lgbm_objective,\n",
    "                )\n",
    "                except Exception as error:\n",
    "                    print(\n",
    "                        Fore.RED + classifiers[self.predictor],\n",
    "                        \"Model Train Failed with error: \",\n",
    "                        error,\n",
    "                        \"\\n\",\n",
    "                    )\n",
    "                try:\n",
    "                    self.classifier.fit(self.X_train, self.y_train)\n",
    "                    self.y_pred = self.classifier.predict(self.X_val)\n",
    "                    if self.predictor == \"ann\":\n",
    "                        self.y_pred = (self.y_pred > 0.5).astype(\"int32\")\n",
    "                    self.accuracy = accuracy_score(self.y_val, self.y_pred)\n",
    "                    self.acc.append(self.accuracy * 100)\n",
    "                    self.classifier_name, self.kfold_accuracy = kfold(\n",
    "                        self.classifier,\n",
    "                        self.predictor,\n",
    "                        self.X_train,\n",
    "                        self.y_train,\n",
    "                        self.cv_folds,\n",
    "                        all_mode=True,\n",
    "                    )\n",
    "                    self.kfoldacc.append(self.kfold_accuracy)\n",
    "                    self.classifier_model.append(self.classifier)\n",
    "                except Exception as error:\n",
    "                    print(\n",
    "                        classifiers[self.predictor],\n",
    "                        \"Evaluation Failed with error: \",\n",
    "                        error,\n",
    "                        \"\\n\",\n",
    "                    )\n",
    "                if self.tune:\n",
    "                    self.__tuner(all_mode=True, single_mode=False)\n",
    "\n",
    "        self.result_df[\"Accuracy\"] = self.acc\n",
    "        self.result_df[\"KFold Accuracy\"] = self.kfoldacc\n",
    "        self.result_df[\"Model\"] = self.classifier_model\n",
    "        if self.tune:\n",
    "            self.result_df[\"Best Parameters\"] = self.bestparams\n",
    "            self.result_df[\"Best Accuracy\"] = self.bestacc\n",
    "            self.best_classifier = Best(\n",
    "                self.result_df.loc[self.result_df[\"Best Accuracy\"].idxmax()],\n",
    "                self.tune,\n",
    "            )\n",
    "        else:\n",
    "            self.best_classifier = Best(\n",
    "                self.result_df.loc[self.result_df[\"KFold Accuracy\"].idxmax()], self.tune\n",
    "            )\n",
    "        print(Fore.GREEN + \"Training Done [\", \"\\u2713\", \"]\\n\")\n",
    "        print(Fore.CYAN + \"Results Below\\n\")\n",
    "        display(self.result_df)\n",
    "        print(Fore.GREEN + \"\\nCompleted LuciferML Run [\", \"\\u2713\", \"]\\n\")\n",
    "        if len(self.model_to_predict) > 1:\n",
    "            self.best_classifier_path, self.scaler_path = self.save(\n",
    "                best=True, model=self.best_classifier.model, scaler=self.sc\n",
    "            )\n",
    "            print(\n",
    "                Fore.CYAN\n",
    "                + \"Saved Best Model to {} and its scaler to {}\".format(\n",
    "                    self.best_classifier_path, self.scaler_path\n",
    "                ),\n",
    "                \"\\n\",\n",
    "            )\n",
    "        self.end = time.time()\n",
    "        final_time = self.end - self.start\n",
    "        print(Fore.BLUE + \"Time Elapsed : \", f\"{final_time:.2f}\", \"seconds \\n\")\n",
    "        return\n",
    "\n",
    "    def __tuner(self, all_mode=False, single_mode=False):\n",
    "        if not all_mode:\n",
    "            print(Fore.YELLOW + \"Tuning Started [*]\\n\")\n",
    "        if not self.predictor == \"nb\":\n",
    "            (\n",
    "                self.best_params,\n",
    "                self.best_accuracy,\n",
    "                self.best_trained_model,\n",
    "            ) = luciferml_tuner(\n",
    "                self.predictor,\n",
    "                self.objective,\n",
    "                self.n_trials,\n",
    "                self.sampler,\n",
    "                self.direction,\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                self.cv_folds,\n",
    "                self.random_state,\n",
    "                self.metric,\n",
    "                all_mode=all_mode,\n",
    "            )\n",
    "        if self.predictor == \"nb\":\n",
    "            self.best_params = \"Not Applicable\"\n",
    "            self.best_accuracy = 0\n",
    "        self.bestparams.append(self.best_params)\n",
    "        self.bestacc.append(self.best_accuracy * 100)\n",
    "        self.tuned_trained_model.append(self.best_trained_model)\n",
    "        if not all_mode or single_mode:\n",
    "            print(Fore.GREEN + \"Tuning Done [\", \"\\u2713\", \"]\\n\")\n",
    "\n",
    "    def result(self):\n",
    "        \"\"\"[Makes a dictionary containing Classifier Name, K-Fold CV Accuracy, RMSE, Prediction set.]\n",
    "\n",
    "        Returns:\n",
    "            [dict]: [Dictionary containing :\n",
    "                        - \"Classifier\" - Classifier Name\n",
    "                        - \"Accuracy\" - KFold CV Accuracy\n",
    "                        - \"YPred\" - Array for Prediction set\n",
    "                        ]\n",
    "            [dataframe] : [Dataset containing accuracy and best_params\n",
    "                            for all predictors only when predictor = 'all' is used\n",
    "                            ]\n",
    "        \"\"\"\n",
    "        if not self.pred_mode == \"all\":\n",
    "            self.reg_result[\"Classifier\"] = self.classifier_name\n",
    "            self.reg_result[\"Accuracy\"] = self.kfold_accuracy\n",
    "            self.reg_result[\"YPred\"] = self.y_pred\n",
    "\n",
    "            return self.reg_result\n",
    "        if self.pred_mode == \"all\":\n",
    "            return self.result_df\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"[Takes test set and returns predictions for that test set]\n",
    "\n",
    "        Args:\n",
    "            X_test ([Array]): [Array Containing Test Set]\n",
    "\n",
    "        Returns:\n",
    "            [Array]: [Predicted set for given test set]\n",
    "        \"\"\"\n",
    "        if not self.pred_mode == \"all\":\n",
    "            X_test = np.array(X_test)\n",
    "            if X_test.ndim == 1:\n",
    "                X_test = X_test.reshape(1, -1)\n",
    "\n",
    "            y_test = self.classifier.predict(self.sc.transform(X_test))\n",
    "\n",
    "            return y_test\n",
    "        if self.pred_mode == \"all\":\n",
    "            raise TypeError(\"Predict is only applicable on single predictor\")\n",
    "\n",
    "    def save(self, path=None, best=False, **kwargs):\n",
    "        \"\"\"\n",
    "        Saves the model and its scaler to a file provided with a path.\n",
    "        If no path is provided will create a directory named\n",
    "        lucifer_ml_info/models/ and lucifer_ml_info/scaler/ in current working directory\n",
    "        Args:\n",
    "            path ([list]): [List containing path to save the model and scaler.]\n",
    "                Example: path = [\"model.pkl\", \"scaler.pkl\"]\n",
    "\n",
    "        Returns:\n",
    "            Path to the saved model and its scaler.\n",
    "        \"\"\"\n",
    "        if not type(path) == list and path != None:\n",
    "            raise TypeError(\"Path must be a list\")\n",
    "        if self.pred_mode == \"all\" and best == False:\n",
    "            raise TypeError(\"Cannot save model for all predictors\")\n",
    "        dir_path_model = path[0] if path else \"lucifer_ml_info/models/classifier/\"\n",
    "        dir_path_scaler = path[1] if path else \"lucifer_ml_info/scalers/classifier/\"\n",
    "        model_name = classifiers[self.predictor].replace(\" \", \"_\")\n",
    "        if best:\n",
    "            dir_path_model = \"lucifer_ml_info/best/classifier/models/\"\n",
    "            dir_path_scaler = \"lucifer_ml_info/best/classifier/scalers/\"\n",
    "            model_name = self.best_classifier.name.replace(\" \", \"_\")\n",
    "        os.makedirs(dir_path_model, exist_ok=True)\n",
    "        os.makedirs(dir_path_scaler, exist_ok=True)\n",
    "        timestamp = str(int(time.time()))\n",
    "        path_model = dir_path_model + model_name + \"_\" + timestamp + \".pkl\"\n",
    "        path_scaler = (\n",
    "            dir_path_scaler + model_name + \"_\" + \"Scaler\" + \"_\" + timestamp + \".pkl\"\n",
    "        )\n",
    "        if (\n",
    "            not kwargs.get(\"model\")\n",
    "            and not kwargs.get(\"best\")\n",
    "            and not kwargs.get(\"scaler\")\n",
    "        ):\n",
    "            dump(self.classifier, open(path_model, \"wb\"))\n",
    "            dump(self.sc, open(path_scaler, \"wb\"))\n",
    "        else:\n",
    "            dump(kwargs.get(\"model\"), open(path_model, \"wb\"))\n",
    "            dump(kwargs.get(\"scaler\"), open(path_scaler, \"wb\"))\n",
    "        if not best:\n",
    "            print(\"Model Saved at {} and Scaler at {}\".format(path_model, path_scaler))\n",
    "        return path_model, path_scaler\n",
    "\n",
    "    def __load(self, path=None):\n",
    "        \"\"\"\n",
    "        Loads model and scaler from the specified path\n",
    "        Args:\n",
    "            path ([list]): [List containing path to load the model and scaler.]\n",
    "                Example: path = [\"model.pkl\", \"scaler.pkl\"]\n",
    "\n",
    "        Returns:\n",
    "            [Model] : [Loaded model]\n",
    "            [Scaler] : [Loaded scaler]\n",
    "        \"\"\"\n",
    "\n",
    "        model_path = path[0] if path[0] else None\n",
    "        scaler_path = path[1] if path[1] else None\n",
    "        if not \".pkl\" in model_path and not model_path == None:\n",
    "            raise TypeError(\n",
    "                \"[Error] Model Filetype not supported. Please use .pkl type \"\n",
    "            )\n",
    "        if not \".pkl\" in scaler_path and not scaler_path == None:\n",
    "            raise TypeError(\n",
    "                \"[Error] Scaler Filetype not supported. Please use .pkl type \"\n",
    "            )\n",
    "        if model_path != None and scaler_path != None:\n",
    "            model = load(open(model_path, \"rb\"))\n",
    "            scaler = load(open(scaler_path, \"rb\"))\n",
    "            print(\n",
    "                Fore.GREEN\n",
    "                + \"[Info] Model and Scaler Loaded from {} and {}\".format(\n",
    "                    model_path, scaler_path\n",
    "                )\n",
    "            )\n",
    "            return model, scaler\n",
    "        elif model_path != None and scaler_path == None:\n",
    "            model = load(open(model_path, \"rb\"))\n",
    "            print(Fore.GREEN + \"[Info] Model Loaded from {}\".format(model_path))\n",
    "            return model\n",
    "        elif model_path == None and scaler_path != None:\n",
    "            scaler = load(open(scaler_path, \"rb\"))\n",
    "            print(Fore.GREEN + \"[Info] Scaler Loaded from {}\".format(scaler_path))\n",
    "            return scaler\n",
    "        else:\n",
    "            raise ValueError(\"No path specified.Please provide actual path\\n\")\n",
    "\n",
    "    def imp_features(self, extensive=False, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Returns the importance features of the dataset\n",
    "\n",
    "        Args:\n",
    "\n",
    "            extensive (bool): [If True shows the importance of all features exitensively and will take more time] [default = False]\n",
    "            **args: [Additional arguments]\n",
    "            **kwargs: [Additional keyword arguments]\n",
    "        \"\"\"\n",
    "        if self.original_predictor == \"all\":\n",
    "            raise TypeError(\n",
    "                \"[Error] This method is only applicable on single predictor\"\n",
    "            )\n",
    "        if not extensive:\n",
    "            self.preprocesspermutational_feature_imp(\n",
    "                self.features, self.X_train, self.y_train, model=self.classifier\n",
    "            )\n",
    "        if extensive:\n",
    "            self.preprocessshap_feature_imp(\n",
    "                self.features, self.X_train, model=self.classifier, *args, **kwargs\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128c684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
